{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of O75116_v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aboagyeso/v2_code/blob/master/Copy_of_Copy_of_O75116_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_QFqo42aiX",
        "colab_type": "code",
        "outputId": "f9910ea0-b258-4206-e3e6-709927abc1c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Embedding, Conv1D, MaxPooling1D, GRU\n",
        "from keras import regularizers\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import LSTM\n",
        "import numpy\n",
        "import csv\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import random \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "maxlen = 100\n",
        "batch_size = 128\n",
        "\n",
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_training/v2/O75116.csv\", delimiter=\",\")\n",
        "#X_train = dataset.iloc[:,0:1].values\n",
        "#y_train = dataset.iloc[:,1:2].values\n",
        "X_train = dataset[['smiles']].values\n",
        "y_train = dataset[['pAc']].values\n",
        "\n",
        "for p in range (X_train.shape[0]):\n",
        "  s = X_train[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_train[p,0] = s\n",
        "X_train = X_train[:,0]  \n",
        "#y_train = y_train[:,0]\n",
        "X_train = X_train.tolist()\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=100)\n",
        "print(X_train)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 6 5 1]\n",
            " [0 0 0 ... 3 1 4]\n",
            " [0 0 0 ... 1 2 4]\n",
            " ...\n",
            " [0 0 0 ... 4 1 1]\n",
            " [0 0 0 ... 1 4 3]\n",
            " [0 0 0 ... 1 4 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAGViFDk5r1j",
        "colab_type": "code",
        "outputId": "aefc3b99-6f03-41c6-fbc9-ce1848205f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_validation/smilesO75116.csv\", delimiter=\",\")\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "X_test = dataset[['smiles']].values\n",
        "y_test = dataset[['pAc']].values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "for p in range (X_test.shape[0]):\n",
        "  s = X_test[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_test[p,0] = s\n",
        "X_test = X_test[:,0]  \n",
        "#y_test = y_test[:,0]\n",
        "X_test = X_test.tolist()\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test, maxlen=100)\n",
        "#print(X_test)\n",
        "#print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(100, 128, input_length=100))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(0.001))\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=20)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 20:28:14.285675 140011147626368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0727 20:28:14.313514 140011147626368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 20:28:14.316085 140011147626368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0727 20:28:14.706341 140011147626368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0727 20:28:14.981369 140011147626368 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0727 20:28:15.924352 140011147626368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0727 20:28:16.094825 140011147626368 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "12280/12280 [==============================] - 30s 2ms/step - loss: 6.6397\n",
            "Epoch 2/20\n",
            "12280/12280 [==============================] - 27s 2ms/step - loss: 2.0673\n",
            "Epoch 3/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0610\n",
            "Epoch 4/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0567\n",
            "Epoch 5/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0500\n",
            "Epoch 6/20\n",
            "12280/12280 [==============================] - 27s 2ms/step - loss: 2.0513\n",
            "Epoch 7/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0495\n",
            "Epoch 8/20\n",
            "12280/12280 [==============================] - 27s 2ms/step - loss: 2.0443\n",
            "Epoch 9/20\n",
            "12280/12280 [==============================] - 27s 2ms/step - loss: 2.0433\n",
            "Epoch 10/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0413\n",
            "Epoch 11/20\n",
            "12280/12280 [==============================] - 27s 2ms/step - loss: 2.0436\n",
            "Epoch 12/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0431\n",
            "Epoch 13/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0436\n",
            "Epoch 14/20\n",
            "12280/12280 [==============================] - 27s 2ms/step - loss: 2.0371\n",
            "Epoch 15/20\n",
            "12280/12280 [==============================] - 27s 2ms/step - loss: 2.0400\n",
            "Epoch 16/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0387\n",
            "Epoch 17/20\n",
            "12280/12280 [==============================] - 27s 2ms/step - loss: 2.0426\n",
            "Epoch 18/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0431\n",
            "Epoch 19/20\n",
            "12280/12280 [==============================] - 28s 2ms/step - loss: 2.0389\n",
            "Epoch 20/20\n",
            "12280/12280 [==============================] - 23s 2ms/step - loss: 2.0262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f568f760ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QojRQg6i4Kfa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "30858fad-296d-4a38-900c-3a8f28489b96"
      },
      "source": [
        "score = model.evaluate(X_test, y_test,\n",
        "                            batch_size=128)\n",
        "print('Test score:', score)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2_score = r2_score(y_test, predictions)\n",
        "\n",
        "print(str(mae)+\"\\t\"+str(mse)+\"\\t\"+str(r2_score))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r120/120 [==============================] - 0s 1ms/step\n",
            "Test score: 2.0293266773223877\n",
            "1.0889861605962117\t2.029326616314266\t0.11587439862034532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WYlIvMH4KTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zPbT3cy4J60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}