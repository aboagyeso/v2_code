{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of Copy of P49841_V2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aboagyeso/v2_code/blob/master/Copy_of_Copy_of_Copy_of_Copy_of_P49841_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH_QFqo42aiX",
        "colab_type": "code",
        "outputId": "22d1c004-5709-4b69-c80d-4ca7c41bca8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Embedding, Conv1D, MaxPooling1D, GRU\n",
        "from keras import regularizers\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import LSTM\n",
        "import numpy\n",
        "import csv\n",
        "import pandas as pd\n",
        "import hashlib\n",
        "import random \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "maxlen = 100\n",
        "batch_size = 128\n",
        "\n",
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_training/v2/P49841.csv\", delimiter=\",\")\n",
        "#X_train = dataset.iloc[:,0:1].values\n",
        "#y_train = dataset.iloc[:,1:2].values\n",
        "X_train = dataset[['smiles']].values\n",
        "y_train = dataset[['pAc']].values\n",
        "\n",
        "for p in range (X_train.shape[0]):\n",
        "  s = X_train[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_train[p,0] = s\n",
        "X_train = X_train[:,0]  \n",
        "#y_train = y_train[:,0]\n",
        "X_train = X_train.tolist()\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_train = pad_sequences(X_train, maxlen=100)\n",
        "print(X_train)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0 ... 12  2  7]\n",
            " [ 0  0  0 ...  1  6  3]\n",
            " [ 0  0  0 ...  1  4  3]\n",
            " ...\n",
            " [ 0  0  0 ...  4  1  3]\n",
            " [ 0  0  0 ...  5  1  6]\n",
            " [ 0  0  0 ...  1  3  5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAGViFDk5r1j",
        "colab_type": "code",
        "outputId": "353c81b0-57ca-4280-8d95-84bfa44850c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/aboagyeso/LSTM_SMILES/master/Data/smiles_validation/smilesP49841.csv\", delimiter=\",\")\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "X_test = dataset[['smiles']].values\n",
        "y_test = dataset[['pAc']].values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#X_test = dataset.iloc[:,0:1].values\n",
        "#y_test = dataset.iloc[:,1:2].values\n",
        "\n",
        "for p in range (X_test.shape[0]):\n",
        "  s = X_test[p,0]\n",
        "  s = s.replace(\"[nH]\",\"A\")\n",
        "  s = s.replace(\"Cl\",\"L\")\n",
        "  s = s.replace(\"Br\",\"R\")\n",
        "  s = s.replace(\"[C@]\",\"C\")\n",
        "  s = s.replace(\"[C@@]\",\"C\")\n",
        "  s = s.replace(\"[C@@H]\",\"C\")\n",
        "  s =[s[i:i+1] for i in range(0,len(s),1)]\n",
        "  s = \" \".join(s)\n",
        "  X_test[p,0] = s\n",
        "X_test = X_test[:,0]  \n",
        "#y_test = y_test[:,0]\n",
        "X_test = X_test.tolist()\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test, maxlen=100)\n",
        "#print(X_test)\n",
        "#print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(100, 128, input_length=100))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(100, activation='tanh'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "model.compile(loss='mean_squared_error', optimizer=Adam(0.001))\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=20)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0727 23:05:23.828665 140531364263808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0727 23:05:23.842747 140531364263808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0727 23:05:23.845049 140531364263808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0727 23:05:24.104811 140531364263808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0727 23:05:24.297247 140531364263808 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0727 23:05:24.857167 140531364263808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0727 23:05:24.971142 140531364263808 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15690/15690 [==============================] - 26s 2ms/step - loss: 4.2948\n",
            "Epoch 2/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.5272\n",
            "Epoch 3/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.5178\n",
            "Epoch 4/20\n",
            "15690/15690 [==============================] - 37s 2ms/step - loss: 1.5036\n",
            "Epoch 5/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.4552\n",
            "Epoch 6/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.3980\n",
            "Epoch 7/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.3491\n",
            "Epoch 8/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.3287\n",
            "Epoch 9/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.3262\n",
            "Epoch 10/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.3157\n",
            "Epoch 11/20\n",
            "15690/15690 [==============================] - 37s 2ms/step - loss: 1.2991\n",
            "Epoch 12/20\n",
            "15690/15690 [==============================] - 37s 2ms/step - loss: 1.3096\n",
            "Epoch 13/20\n",
            "15690/15690 [==============================] - 37s 2ms/step - loss: 1.2815\n",
            "Epoch 14/20\n",
            "15690/15690 [==============================] - 37s 2ms/step - loss: 1.2628\n",
            "Epoch 15/20\n",
            "15690/15690 [==============================] - 37s 2ms/step - loss: 1.2520\n",
            "Epoch 16/20\n",
            "15690/15690 [==============================] - 37s 2ms/step - loss: 1.2458\n",
            "Epoch 17/20\n",
            "15690/15690 [==============================] - 40s 3ms/step - loss: 1.2360\n",
            "Epoch 18/20\n",
            "15690/15690 [==============================] - 39s 2ms/step - loss: 1.2263\n",
            "Epoch 19/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.2103\n",
            "Epoch 20/20\n",
            "15690/15690 [==============================] - 38s 2ms/step - loss: 1.1760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcfaec21ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QojRQg6i4Kfa",
        "colab_type": "code",
        "outputId": "664bf0f3-62c5-43cd-f01d-9eb510c3c1ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test,\n",
        "                            batch_size=128)\n",
        "print('Test score:', score)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "r2_score = r2_score(y_test, predictions)\n",
        "\n",
        "print(str(mae)+\"\\t\"+str(mse)+\"\\t\"+str(r2_score))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 3ms/step\n",
            "Test score: 1.4596188812498834\n",
            "0.9129037841551585\t1.459618909434942\t0.14286440515749566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WYlIvMH4KTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zPbT3cy4J60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}